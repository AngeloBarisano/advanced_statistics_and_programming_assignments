---
title: "assignment_1_angelo_barisano_final"
output: html_document
date: '2022-09-13'
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```



```{r import data & set wkdir, include=FALSE}
# clear environment
rm(list=ls())

# import the necessary libraries
library("tidyverse")
library("stargazer")
library("tidyverse")
library("reshape")
library("Hmisc")
library("ggplot2")
library("dplyr")
library("moments")
library ("lm.beta")
library("fastDummies")
library("gtsummary")
library("stringr")
library("extrafont")
loadfonts()




setwd("/home/angelo/Documents/Uni/Courses/Advanced Statistics and programming/Assignments/assignment1")

df <- read.csv("Data/train.csv", header= TRUE, sep= ",")

```

### Setting up a small function to fix the stargazer output
``` {r fix stargazer}
# credit: https://stackoverflow.com/questions/63959113/how-can-we-display-f-statistic-degrees-of-freedom-in-two-lines


show_F_in_two_lines <- function(stargazer) {
  # `Stringr` works better than base's regex 
  require(stringr)

  # If you remove `capture.output()`, not only the modified LaTeX code 
  # but also the original code would show up
  stargazer <- stargazer |>
    capture.output()

  # Reuse the index in which F-statistics are displayed
  position_F <- str_which(stargazer, "F Statistic")

  # Extract only F-statistics
  Fs <- stargazer[position_F] |>
    str_replace_all("\\(.*?\\)", "")

  # Extract only df values and make a new line for them
  dfs <- stargazer[position_F] |>
    str_extract_all("\\(.*?\\)") |>
    unlist() |>
    (
      \(dfs)
      paste0(" & ", dfs, collapse = "")
    )() |>
    paste0(" \\\\")

  # Reuse table elements that are specified
  # after the index of F-statistics
  after_Fs <- stargazer[-seq_len(position_F)]

  c(
    stargazer[seq_len(position_F - 1)],
    Fs,
    dfs,
    after_Fs
  ) |>
    cat(sep = "\n")
}
```



# Inspect missing values in the data before changing data types 
#### Eg. string conversion can lead to Null values to be interpreted as strings


```{r missing values inspection}
# display missing values by column
colSums(is.na(df))

# select all columns which have missing data 
which(colSums(is.na(df))>0)
```

```{r prep data}
df_ <- df[, c(
  'Id',
  'SalePrice',
  'MoSold',
  'YrSold',
  'YearRemodAdd',
  'LotArea',
  'GrLivArea',
  'TotalBsmtSF',
  'BldgType',
  'MSZoning',
  'Neighborhood',
  'OverallQual',
  'OverallCond'
)]

# create the interesting varaibles
df_$tot_liv_area <- df_$GrLivArea + df_$TotalBsmtSF

# time since remodeling at year of sale in years
df_$y_since_rem <- df_$YrSold - df_$YearRemodAdd



# adjust for family homes
# the distinction made here is simply that:
# stand alone house vs multiple houses together
match_df = data.frame(
  old = c("1Fam", "2fmCon", "Duplex",  "Twnhs", "TwnhsE"),
  new = c(
    "Single Family Home",
    "Multi-Unit Homes",
    "Multi-Unit Homes",
    "Multi-Unit Homes",
    "Multi-Unit Homes"
  )
)

df_ <-
  df_ %>% mutate(Building_type = match_df$new[match(BldgType, match_df$old)])



# group zoning
#' I have decided to leave the groups as small groups sizes are only a problem for anova
#' https://stats.stackexchange.com/questions/219071/sample-size-of-the-levels-of-a-categorical-variables -- CITE!
#' https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229345
#' Additionally: the plot shows that even if these groups are small, they do not scatter that much
match_df = data.frame(
  old = c("C (all)", "FV", "RH", "RL", "RM"),
  new = c(
    "Commercial",
    "Floating Village",
    "High Density",
    "Low Density",
    "Moderate Density"
  )
)

df_ <-
  df_ %>% mutate(MSZoning = match_df$new[match(MSZoning, match_df$old)])

#' however, further analysis will show that these two groups are quite comparable; so for the purpose of this analysis they are merged as well
#' Commercial and FV are too different to even be considered merged
match_df = data.frame(
  old = c("Commercial", "Floating Village", "High Density", "Low Density", "Moderate Density"),
  new = c(
    "Commercial",
    "Floating Village",
    "Moderate2High Density",
    "Low Density",
    "Moderate2High Density"
  )
)

df_ <-
  df_ %>% mutate(MSZoning_gr = match_df$new[match(MSZoning, match_df$old)])

# fix y_since_rem
df[df$y_since_rem < 0, "y_since_rem"] <- 0

```



```{r inspect dypes of the variables at hand}
# adjust the scale of saleprice for easier handling
df_$SalePrice <- df_$SalePrice / 1000

# to make it clear that only certain operations can be performed on the data
# ID should be a character as string/factor operations are resptrictive by design
# i.e. no mathematical operations
df_$Id <- as.character(df_$Id)

# The month sold shoul also be considered a factor for the same reason before
df_$MoSold <- as.factor(df_$MoSold)
df_$YrSold <- as.factor(df_$YrSold)

# these are just standard variables to be converted to factors
df_$Neighborhood <- as.factor(df_$Neighborhood)
df_$BldgType <- as.factor(df_$BldgType)
df_$MSZoning <- as.factor(df_$MSZoning)

# OverallQual can be interpreted as both categorical and numeric; It wil be further elaobrated upon
df_$OverallQual_cat <- as.factor(df_$OverallQual)


# drop some columns which are now no logner needed
df_ = df_[, !(names(df_) %in% c("YearRemodAdd", "TotalBsmtSF", "GrLivArea"))]

str(df_)

```




```{r inspect missing values a last time}
# display missing values by column
colSums(is.na(df_))


# select all columns which have missing data 
which(colSums(is.na(df_))>0)

```


```{r stargazer stats}
colnames(df_)


```

```{r stargazer stats}

df_temp <- df_ %>%
  select(-one_of(c('Id', "MoSold", "YrSold", "BldgType")))
print(skewness(df_temp$SalePrice))

stargazer(
  df_temp,
  type = 'text',
  omit.summary.stat = c("N"),
  summary.stat = c("mean", "sd", "min", "p25", "median", "p75", "max")
  , title="Descriptive Statistics of Numeric Indepdenent and Dependent Varaible",
  covariate.labels = 
        c("SalePrice", "Lot Area", "Quality", "Condition",
          "Total Living Space", "Years Since Remodeling")
  # , initial.zero = F
  # ,single.row=TRUE)
)

stargazer(
  df_temp,
  # type = 'text',
  omit.summary.stat = c("N"),
  summary.stat = c("mean", "sd", "min", "p25", "median", "p75", "max")
  , title="Descriptive Statistics of Numeric Indepdenent and Dependent Varaible"
  ,
    covariate.labels = 
        c("SalePrice", "Lot Area", "Quality", "Condition",
          "Total Living Space", "Years Since Remodeling")
  # , initial.zero = F
  # ,single.row=TRUE)
)






```



# Plots

```{r First Hypothesis Plot}
# livingSpace by SalePrice
scatter <- ggplot(df_, aes(tot_liv_area, SalePrice))
scatter + geom_point() + geom_smooth(method = "lm", color = "Red")  + geom_smooth() + labs(x = 'Living space in square feet', y = "Sale Price in 1000s")+ xlim(0, 7000)  + theme(
  axis.text.x = element_text(size = 17,family="LM Roman 10"),
  axis.text.y = element_text(size = 17, family="LM Roman 10"),
  axis.title = element_text(size = 20, family="LM Roman 10")
)     
#+ ggtitle("Sale Price by Living Space in square feet")
ggsave("h1.jpg")
#' Add Descritption: Two outliers left out for representative reasons 

# smooth the plot

scatter <- ggplot(df_, aes(tot_liv_area, SalePrice))
scatter + geom_point() + geom_smooth() + labs(x = 'Living space in square feet', y = "Sale Price in 1000s")+ xlim(0, 7000) 

#' Hypothesis 1: Total Living Space (IV) has a positive effect (potitive association with) on Sales Price (DV)

```

```{r inspect whether MSZones can be merged to ease the analysis and increase readablity}


# Only inspect high density & Medium density to see if they ar compatible 
scatter <-
  ggplot(subset(df_, MSZoning == "High Density" |MSZoning == "Moderate Density"  ), aes(tot_liv_area, SalePrice, colour = MSZoning))

scatter + geom_point() + geom_smooth(method = "lm", aes(fill = "MSZoning"), alpha = 0.1) + labs(x = 'Living space in square feet', y = "Sale Price in 1000s", color = 'MSZoning')  #+ggtitle("Sale Price by Zone")
#' interestingly: Moderate and High density appear to be quite comparable


bar <- ggplot(df_, aes(MSZoning, SalePrice))

bar + stat_summary(
  fun = mean,
  geom = "bar",
  fill = 'white',
  colour = "Black"
) + stat_summary(fun.data = mean_cl_normal, geom = "pointrange") + labs(x = 'Zoning', y = 'Sale Price')

#' Additionally, High and Moderate density are also in this case quite comparable in all their statistics
#' As such, one can assume that these two groups might be comparable and can be merged
#' However, there might be other reasons underlying this issue; such as the small sample size of High density 
```


```{r Second Hypothesis Plot}
# now drill down


scatter <-
  ggplot(df_, aes(tot_liv_area, SalePrice, colour = MSZoning))
scatter + geom_point() + geom_smooth(method = "lm", alpha = 0.1) + labs(x = 'Living space in square feet', y = "Sale Price in 1000s") + xlim(0, 7000) + theme_set(theme_bw()+ theme(legend.position = "bottom"))  + theme(
  axis.text.x = element_text(size = 15, family="LM Roman 10"),
  axis.text.y = element_text(size = 15, family="LM Roman 10"),
  axis.title = element_text(size = 20, family="LM Roman 10"),
  legend.text = element_text(size = 14, family="LM Roman 10")
)     


#+ ggtitle("Sale Price by Living Space in square feet subsectioned by Zone")
ggsave("h2.1.jpg")



# Now obseve the groups we identified before

scatter <-
  ggplot(df_,
         aes(tot_liv_area, SalePrice, colour = MSZoning_gr),
         cex.lab = 30)
scatter + geom_point() + geom_smooth(method = "lm", alpha = 0.1) + labs(x = 'Living space in square feet', y = "Sale Price in 1000s", color = 'MSZoning_gr') + xlim(0, 7000)  + theme_set(theme_bw() + theme(legend.position = "bottom")) + theme(
  axis.text.x = element_text(size = 17 ,family="LM Roman 10"),
  axis.text.y = element_text(size = 17,family="LM Roman 10"),
  axis.title = element_text(size = 20,family="LM Roman 10"),
  legend.text = element_text(size = 16,family="LM Roman 10")
)     

ggsave("h2.2.jpg")

#+ ggtitle("Sale Price by Living Space in square feet subsectioned by Zone")




#' While not incredibly strong we would expect the effect of Lining Space on Sale Price to be stronger for Low density 
#' areas than for High or Medium; in this case Moderate2High density

#' Hypothesis 2: The effect of Total Living Space on Sales Price is stronger (association is stronger) for Low Density zones than for Moderate OR High Density areas; A second part of this analysis invols Moderate2High 

```



```{r plots, echo=FALSE}
# Subanalysis; Neighborhoods & Clusters

scatter <- ggplot(df_, aes(tot_liv_area, SalePrice))
scatter + geom_point() + geom_smooth(method = "lm", color = "Red") + labs(x = 'Living space in square feet', y = "Sale Price in 1000s")


scatter <- ggplot(df_, aes(tot_liv_area, SalePrice, colour = Neighborhood))
scatter + geom_point() + geom_smooth(method = "lm", aes(fill = "Neighborhood"), alpha = 0.1) + labs(x = 'Living space in square feet', y = "Sale Price in 1000s", color = 'Neighborhood')


scatter <- ggplot(df_, aes(tot_liv_area, SalePrice))
scatter + geom_point() + geom_smooth(method = "lm", color = "Red") + labs(x = 'Living space in square feet', y = "Sale Price in 1000s") + xlim(0, 7000)


scatter <- ggplot(df_, aes(tot_liv_area, SalePrice, colour = Neighborhood))
scatter + geom_point() + geom_smooth(method = "lm", aes(fill = "Neighborhood"), alpha = 0.1) + labs(x = 'Living space in square feet', y = "Sale Price in 1000s", color = 'Neighborhood') + xlim(0, 7000)

df_subset <-
  subset(
    df_,
    Neighborhood == "NoRidge" |
      Neighborhood == "OldTown" |
      Neighborhood == "CollgCr" |
      Neighborhood == "NridgHt" 
  )

scatter <- ggplot(df_subset, aes(tot_liv_area, SalePrice))
scatter + geom_point() + geom_smooth(method = "lm", color = "Red") + labs(x = 'Living space in square feet', y = "Sale Price in 1000s") + xlim(0, 7000)


scatter <- ggplot(df_subset, aes(tot_liv_area, SalePrice, colour = Neighborhood))
scatter + geom_point() + geom_smooth(method = "lm", aes(fill = "Neighborhood"), alpha = 0.1) + labs(x = 'Living space in square feet', y = "Sale Price in 1000s", color = 'Neighborhood') + xlim(0, 7000)

#' generally, as can be seen in these polots, the associations tend to cluster under certain neighborhoods and seem to be quite linear; However, this is less clear due to the amount of Neighborhoods and visually, this variable is not easy to be analysed
#' Additionally, it is to be expected that this variable would have a confounder possibly explaining a lot of the variance in the sales price; Crime by neighborhood
#' this necessitates another study to this end with other data 
```


```{r Control for quality and age of the house in general; hypothesis 3, echo=FALSE}
#' the association betwen the state of the house (in terms of qualtiy) and the years since it was renovated/remodeled 
#' is clear considering the first plot 
scatter <- ggplot(df_, aes(y_since_rem, SalePrice))
scatter + geom_point() + geom_smooth(method = "lm", aes(fill = "y_since_rem"), alpha = 0.4) + labs(x = 'Time Since last Remodeling at point of sale', y = "Sale Price in 1000s")
#' Increasing cears since the house was remodeled (at time of sale of house) has a negative association with Sale price; as is to be expected


#' subseqeutnly, the connection between quality of the house, which represents its features and the quality of the house as 
#' a whole then might be impacted by the years since remodeling
#' 
#' The interpretation would follow as: For eg Qualitygroup2 compared to quality group1; for an increase in time since remodeling, the association of Qualitygroup2 with Sale price will decrease by amount X
#' 
#' What is interesting with this question is that it opens up: WHEN does the quality get reduced
#' Furthermore, when treating qualtiy as a numeric variable, a similar effect can be observed, as will be demonstrated later 
#' 
#' finally, it is notable that ALL categories are more negative than the first category in this moderation term. This was to be expected; which suggests that overall higher quality corresponds with "more recent or more modern houses"


ggplot(df_, aes(x = OverallQual_cat, y = SalePrice)) +
  geom_boxplot()+  xlab("Quality of the property") + ylab("Sale Price in 1000s") + labs(size = "Years Since Remodeling")





ggplot(df_, aes(x = OverallQual, y = SalePrice)) +
  geom_point(aes(size = y_since_rem))+  xlab("Quality of the property") + ylab("Sale Price in 1000s") + theme_set(theme_bw()+ theme(legend.position = "bottom")) + labs(size = "Years Since Remodeling",family="LM Roman 10")  + theme(text=element_text(family="LM Roman 10"),
  axis.text.x = element_text(size = 17,family="LM Roman 10"),
  axis.text.y = element_text(size = 17,family="LM Roman 10"),
  axis.title = element_text(size = 20,family="LM Roman 10"),
  legend.text = element_text(size = 16,family="LM Roman 10")) + scale_x_continuous(breaks = scales::pretty_breaks())

ggsave(file="supplement_appendix_Quality_yearssinceremodeling_sale.jpg")



# this is the hypothesis plot 
scatter <- ggplot(df_, aes(y_since_rem, SalePrice))
scatter + geom_point() + geom_smooth(method = "lm", alpha = 0.4) + theme_set(theme_bw()+ theme(legend.position = "bottom")) + labs(x = 'Time Since last Remodeling at point of sale', y = "Sale Price in 1000s",fill = "Years Since Remodeling")  + theme(text=element_text(family="LM Roman 10"),
  axis.text.x = element_text(size = 17),
  axis.text.y = element_text(size = 17),
  axis.title = element_text(size = 20)
)     
#+ ggtitle("Sale Price by Years Since Remodeling before sale year")
ggsave(file="h3.jpg")


#' This shows that this variable is a great control for the quality of the house and its condition 
 
# As such: Years since remodeling have a negative impact on sales price 
```








```{r hypothesis 3, echo=FALSE}
# Zone on Building type

# the interesting question here is: are stand alone family homes more valuable? than multi-unit homes 

df_$MSZoning
table(df_$BldgType)


bar <- ggplot(df_, aes(BldgType, SalePrice))
bar + stat_summary(
  fun = mean,
  geom = "bar",
  fill = 'white',
  colour = "Black"
) + stat_summary(fun.data = mean_cl_normal, geom = "pointrange") + facet_wrap(~ MSZoning) + labs(x = 'BldgType', y = 'Sale Price') 








```








# Run the regressions

```{r, echo = FALSE}
# QUALITY LINEARITY ASSUMTION

# Preanalysis: is quality as an interval?
# regress all categories of quality on the outcome but leave the lowest out; see wherther there is a step up

# create the dummies
OverallQual_grouped_dummies <- fastDummies::dummy_cols(df_$OverallQual)
#add index column to data frame
OverallQual_grouped_dummies <- tibble::rowid_to_column(OverallQual_grouped_dummies, "Id")


df_y <- df_[c("Id", "SalePrice")] 


# now merge the Y and the dummies for this regression; so that the normal regression equation can be done
jointdataset <- merge(df_y, OverallQual_grouped_dummies, by = 'Id')

# now run the regression compared to the lowest category and look whether there are natural steps between the variabels 
quality_regression_checkup <-
  lm(
    SalePrice ~ 1 + .data_2 + .data_3 + .data_4 + .data_5 + .data_6 + .data_7 + .data_8 + .data_9 + .data_10,
    data = jointdataset
  )

stargazer (
  quality_regression_checkup
, type = 'text'
)

coef(summary(quality_regression_checkup))[, 1:2]

#' arguemtns:
#' 1. like a likert scale
#' 2. the standard errors are extremely constant
#' 3. The plot suggests the same
#' 4. the estimates increase steadilyÂ´
#' PLOT IT!

```






# Task 3

```{r }
# create dummies
df_$low_density_zone <-
  ifelse(df_$MSZoning_gr == "Low Density", 1, 0)

df_$hig_med_density_zone <-
  ifelse(df_$MSZoning_gr == "Moderate2High Density", 1, 0)

df_$commercial_zone <- 
  ifelse(df_$MSZoning_gr == "Commercial", 1, 0)

df_$floating_zone <- 
  ifelse(df_$MSZoning_gr == "Floating Village", 1, 0)


table(df_$MSZoning_gr)

# main model
main_multi_var_model <-
  lm(
    SalePrice ~ 1 + tot_liv_area  + y_since_rem + low_density_zone +  commercial_zone + floating_zone,
    data = df_
  )

main_multi_var_model.beta<-lm.beta(main_multi_var_model)



# With interaction adn quadrartic terms
mulit_var_model <-
  lm(
    SalePrice ~ 1 + tot_liv_area  + y_since_rem + low_density_zone +  commercial_zone + floating_zone + I(tot_liv_area^2)+ tot_liv_area * low_density_zone + tot_liv_area*commercial_zone + tot_liv_area* floating_zone ,
    data = df_
  )

mulit_var_model.beta<-lm.beta(mulit_var_model)


# with covariates and confounders and control
multi_var_model_w_confounders <-
  lm(
    SalePrice ~ 1 + tot_liv_area  + y_since_rem + low_density_zone +  commercial_zone + floating_zone + LotArea + YrSold  + OverallQual_cat + Building_type,
    data = df_
  )
multi_var_model_w_confounders.beta<-lm.beta(multi_var_model_w_confounders)

# with interaction and covariates and confounders and control
multi_var_model_w_confounders_ninteraction <-
  lm(
    SalePrice ~ 1 + tot_liv_area  + y_since_rem + low_density_zone +  commercial_zone + floating_zone + I(tot_liv_area ^2) + tot_liv_area * low_density_zone + tot_liv_area * commercial_zone + tot_liv_area * floating_zone + LotArea + YrSold  + OverallQual_cat + Building_type + LotArea*tot_liv_area ,
    data = df_
  )
multi_var_model_w_confounders_ninteraction.beta <-
  lm.beta(multi_var_model_w_confounders_ninteraction)





stargazer (
  main_multi_var_model,
  mulit_var_model,
  multi_var_model_w_confounders,
  multi_var_model_w_confounders_ninteraction
  , type = 'text'
) |>
  show_F_in_two_lines()




#, keep = 'Dummy1:Dummy2:Dummy3'

```



```{r }



stargazer(
  main_multi_var_model,
  mulit_var_model,
  multi_var_model_w_confounders,
  multi_var_model_w_confounders_ninteraction,
 type = 'text',
  omit = c(
    "YrSold2008",
    "YrSold2009",
    "YrSold2010",
    "OverallQual_cat3",
    "OverallQual_cat4",
    "OverallQual_cat5",
    "OverallQual_cat6",
    "OverallQual_cat7",
    "OverallQual_cat8",
    "OverallQual_cat9",
    "OverallQual_cat10",
    "Building_typeSingle Family Home "
  ),
  
  
            header=FALSE, # to get rid of r package output text

          single.row = FALSE, # to put coefficients and standard errors on same line

          no.space = TRUE, # to remove the spaces after each line of coefficients

          column.sep.width = "3pt", # to reduce column width

          font.size = "small" # to make font size smaller
        # ,float.env = "sidewaystable"
) |>
  show_F_in_two_lines()

```


```{r }



# only compare the two most important models 

stargazer(
  multi_var_model_w_confounders,
  multi_var_model_w_confounders.beta,
  multi_var_model_w_confounders_ninteraction,
  multi_var_model_w_confounders_ninteraction.beta,
  coef = list(
    multi_var_model_w_confounders$coefficients,
    multi_var_model_w_confounders.beta$standardized.coefficients,
    multi_var_model_w_confounders_ninteraction$coefficients,
    multi_var_model_w_confounders_ninteraction.beta$standardized.coefficients
  ),
  p = list (
    coef(summary(multi_var_model_w_confounders))[, 4],
    coef(summary(multi_var_model_w_confounders.beta))[, 5],
    coef(summary(multi_var_model_w_confounders_ninteraction))[, 4],
    coef(summary(multi_var_model_w_confounders_ninteraction.beta))[, 5]
  ),
  type = 'latex',
  omit = c(
    "YrSold2008",
    "YrSold2009",
    "YrSold2010",
    "OverallQual_cat3",
    "OverallQual_cat4",
    "OverallQual_cat5",
    "OverallQual_cat6",
    "OverallQual_cat7",
    "OverallQual_cat8",
    "OverallQual_cat9",
    "OverallQual_cat10",
    "Building_typeSingle Family Home "
  ),
  header = FALSE,
  # to get rid of r package output text
  single.row = FALSE,
  # to put coefficients and standard errors on same line
  # no.space = TRUE,
  # to remove the spaces after each line of coefficients
  column.sep.width = "3pt",
  # to reduce column width
  font.size = "small" # to make font size smaller
  # ,float.env = "sidewaystable"
) |>
  show_F_in_two_lines()



```














